{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Trabalho - NLP Fiap10IA.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HcaUXmYvn2JZ"
      ]
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8bbe98abb34a44a29e1c60e5c2b1df0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7cb7682a9a5f4dbfafa71c1663d1b4fd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c225b28fb2534b9982bcc27dae05f3c3",
              "IPY_MODEL_6bb1865c42e543609c718e53761c1fb3"
            ]
          }
        },
        "7cb7682a9a5f4dbfafa71c1663d1b4fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c225b28fb2534b9982bcc27dae05f3c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_149a6d49306945ada75144067d180d61",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 31653,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 31653,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a5cbc54edf94e279a16e0914f92924e"
          }
        },
        "6bb1865c42e543609c718e53761c1fb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0b0928cec3fd47d8a80d8b780184103b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 31653/31653 [14:04&lt;00:00, 37.47it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5fc0122ec9904bd58128f218e4a1f237"
          }
        },
        "149a6d49306945ada75144067d180d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a5cbc54edf94e279a16e0914f92924e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b0928cec3fd47d8a80d8b780184103b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5fc0122ec9904bd58128f218e4a1f237": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12a70cdd51324d43bcf2abf9f6f78652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1115c3e7b5e54b8c97d7f7703bfba70f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d9a2fd2319f41f192c46d1c7c68b234",
              "IPY_MODEL_dc35bba90f5b4e48992996ea3ea180f4"
            ]
          }
        },
        "1115c3e7b5e54b8c97d7f7703bfba70f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d9a2fd2319f41f192c46d1c7c68b234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7a59366db06f4e1496ecae9c1ae3ffa7",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 31653,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 31653,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b7942268376414fa83309e773be2942"
          }
        },
        "dc35bba90f5b4e48992996ea3ea180f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9d998cc5dd994bcb9564734732241af9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 31653/31653 [06:34&lt;00:00, 80.19it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce719b449b124927842c174bba518988"
          }
        },
        "7a59366db06f4e1496ecae9c1ae3ffa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b7942268376414fa83309e773be2942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d998cc5dd994bcb9564734732241af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce719b449b124927842c174bba518988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ffd4d96031d34928af97fc1c05946131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e88a805b65a6479ab261ab5ecde59d95",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_076fad26c38744ba900fdca9d544d350",
              "IPY_MODEL_5fe4864321a047249be990d39ca50af5"
            ]
          }
        },
        "e88a805b65a6479ab261ab5ecde59d95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "076fad26c38744ba900fdca9d544d350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_271a6c13ff6646bc85727b3e758d933e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 31653,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 31653,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92033cd90cfb4989ab5ff0de38233251"
          }
        },
        "5fe4864321a047249be990d39ca50af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e8ebbbd75ec5450cbd6e83160a167ffa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 31653/31653 [30:53&lt;00:00, 17.08it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5723534749c24f63a4fc15a3e28c5328"
          }
        },
        "271a6c13ff6646bc85727b3e758d933e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92033cd90cfb4989ab5ff0de38233251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8ebbbd75ec5450cbd6e83160a167ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5723534749c24f63a4fc15a3e28c5328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CevaaQ0Ln2FW"
      },
      "source": [
        "# Trabalho Final - Processamento de Linguagem Natural\n",
        "\n",
        "**Professor**: Anderson Dourado\n",
        "\n",
        "**Turma**: 10IA\n",
        "\n",
        "**Integrantes**:\n",
        "\n",
        "    Carlos Eduardo Barbosa - 335518\n",
        "    Daniel Gregoris Guarino - 335398\n",
        "    Fabio de Campos Bordin - 336263\n",
        "    Fernando Bareno Calo - 335434\n",
        "    \n",
        "**Data**: 30/05/2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83afHmYln2FY"
      },
      "source": [
        "### Classificador de Sentimentos\n",
        "\n",
        "Este notebook é o trabalho de criação de um modelo de machine learning que funcione como um **classificador de sentimentos** de crítica de filmes usando técnicas de **Processamento de Linguagem Natural**. As críticas dos filmes foram obtida do site **imdb (Internet Movie Database)** a princípio na lingua inglesa, porém, o classificador deste trabalho deverá funcionar com textos em português, a versão neste idioma já consta no dataset que iremos utilizar. Os sentimentos em relação aos filmes podem ser classificados como **positivo** ou **negativo**. O modelo deverá ser avaliado conforme a métrica F1 Score, que é a média ponderada dos índices **Recall** e **Precisão**, \n",
        "F1 = $$\\begin{equation*} \n",
        "\\frac{2*precision*recall}{precision+recall} sendo a resposta um número entre 0 e 1, sendo que quanto mais perto de 1, mais preciso é o modelo (com os devidos cuidados em relação a overfitting, é claro). No desenvolvimento deste notebook serão realizados diversos experimentos com o intuito de se obter o melhor F1 Score para o classificador.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5FXI7O6-SfW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f9e497f4-a32d-4c51-ec5d-a3e8e3eb6db2"
      },
      "source": [
        "# instalar biblioteca unidecode\n",
        "!pip install unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 16.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSHqmyULn2Fn"
      },
      "source": [
        "# bibliotecas\n",
        "import os\n",
        "import csv\n",
        "import requests\n",
        "from unidecode import unidecode\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.rslp import RSLPStemmer\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXHvKoTLn2Fb"
      },
      "source": [
        "# download do arquivo do dataset\n",
        "url = 'https://dados-ml-pln.s3-sa-east-1.amazonaws.com/imdb-reviews-pt-br.csv'\n",
        "\n",
        "def download_file(url):\n",
        "    request_url = requests.get(url)\n",
        "    if request_url.status_code == requests.codes.OK:\n",
        "        with open('imdb-reviews-pt-br.csv', 'wb') as file:\n",
        "            file.write(request_url.content)\n",
        "    else:\n",
        "        resposta.raise_for_status()\n",
        "        \n",
        "download_file(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9x0drRe-gzW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3504d850-bd40-4079-e730-f96d80d5eea2"
      },
      "source": [
        "# conferir arquivo do dataset no diretório\n",
        "% ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imdb-reviews-pt-br.csv  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGvNpud-n2Fw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7056e95c-77fd-494a-8921-56a62ff0adb5"
      },
      "source": [
        "# abrir e visualizar dataset no Pandas\n",
        "df = pd.read_csv('imdb-reviews-pt-br.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text_en</th>\n",
              "      <th>text_pt</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
              "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... sentiment\n",
              "0   1  ...       neg\n",
              "1   2  ...       neg\n",
              "2   3  ...       neg\n",
              "3   4  ...       neg\n",
              "4   5  ...       neg\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNzVW0Wrn2F4"
      },
      "source": [
        "### Pre Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPsFO8_Vn2GI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "93ecde97-d749-4a8c-b0aa-d4dbeaf16f96"
      },
      "source": [
        "# remover a coluna 'id' do dataset\n",
        "df.drop(labels='id',axis=1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_en</th>\n",
              "      <th>text_pt</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Brass pictures movies is not a fitting word fo...</td>\n",
              "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             text_en  ... sentiment\n",
              "0  Once again Mr. Costner has dragged out a movie...  ...       neg\n",
              "1  This is an example of why the majority of acti...  ...       neg\n",
              "2  First of all I hate those moronic rappers, who...  ...       neg\n",
              "3  Not even the Beatles could write songs everyon...  ...       neg\n",
              "4  Brass pictures movies is not a fitting word fo...  ...       neg\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJftbZuwn2GS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d7d12fc5-7256-4bab-84f6-00505dfc5989"
      },
      "source": [
        "# a classificação de sentimentos será feita na lingua portuguesa, \n",
        "# portanto podemos retirar a feature com texto em inglês e trocar \n",
        "# o nome das feature 'sentiment' e 'text_pt' para a língua portuguesa também\n",
        "df.drop(labels='text_en', axis=1, inplace=True)\n",
        "df.rename(columns={'sentiment': 'sentimento', 'text_pt': 'texto_pt'}, inplace=True)\n",
        "\n",
        "# conferir visualmente se o dataset possui uma coluna a menos e o novo nome\n",
        "# das colunas\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto_pt</th>\n",
              "      <th>sentimento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mais uma vez, o Sr. Costner arrumou um filme p...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Este é um exemplo do motivo pelo qual a maiori...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Primeiro de tudo eu odeio esses raps imbecis, ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Nem mesmo os Beatles puderam escrever músicas ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Filmes de fotos de latão não é uma palavra apr...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            texto_pt sentimento\n",
              "0  Mais uma vez, o Sr. Costner arrumou um filme p...        neg\n",
              "1  Este é um exemplo do motivo pelo qual a maiori...        neg\n",
              "2  Primeiro de tudo eu odeio esses raps imbecis, ...        neg\n",
              "3  Nem mesmo os Beatles puderam escrever músicas ...        neg\n",
              "4  Filmes de fotos de latão não é uma palavra apr...        neg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L_MkmXVn2GZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "73a181ff-7e78-4beb-9fa3-ef318b94cabf"
      },
      "source": [
        "# padronizar os textos em caixa baixa \n",
        "df['texto_pt'] = df.texto_pt.str.lower()\n",
        "df.texto_pt.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    mais uma vez, o sr. costner arrumou um filme p...\n",
              "1    este é um exemplo do motivo pelo qual a maiori...\n",
              "2    primeiro de tudo eu odeio esses raps imbecis, ...\n",
              "3    nem mesmo os beatles puderam escrever músicas ...\n",
              "4    filmes de fotos de latão não é uma palavra apr...\n",
              "Name: texto_pt, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3rKZVp4n2Gg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "28198d5a-c525-4627-b952-2abbb576a8e0"
      },
      "source": [
        "# padronizar texto substituindo palavras acentuadas por não acentuadas\n",
        "# exemplo: latão vira latao, é vira e\n",
        "df['texto_pt'] = df.texto_pt.apply(lambda text: unidecode(text))\n",
        "df.texto_pt.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    mais uma vez, o sr. costner arrumou um filme p...\n",
              "1    este e um exemplo do motivo pelo qual a maiori...\n",
              "2    primeiro de tudo eu odeio esses raps imbecis, ...\n",
              "3    nem mesmo os beatles puderam escrever musicas ...\n",
              "4    filmes de fotos de latao nao e uma palavra apr...\n",
              "Name: texto_pt, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2odwRXZn2Gm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "81f52f55-f929-4057-e69e-b0853324cd30"
      },
      "source": [
        "# verificação da quantidade de cada valor da feature alvo \n",
        "# pos (positivo) e neg (negativo)\n",
        "df.sentimento.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neg    24765\n",
              "pos    24694\n",
              "Name: sentimento, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OPO38ssn2Gr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1fc33819-d275-4880-814c-8492aab3f383"
      },
      "source": [
        "# Agora vamos avaliar a proporção de cada tipo de avaliação\n",
        "negative = df.sentimento.value_counts()[0]\n",
        "positive = df.sentimento.value_counts()[1]\n",
        "total = negative + positive\n",
        "\n",
        "print('Proporção de avaliação neg: %.2f%% \\nProporção de avaliação pos: %.2f%% ' % (negative/total*100, positive/total*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Proporção de avaliação neg: 50.07% \n",
            "Proporção de avaliação pos: 49.93% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jll0D9Zcn2Gz"
      },
      "source": [
        "O dataset está balanceado, temos metade dos filmes avaliados como negativo e a outra metade como positivo, é necessário **manter essa proporção dos dados no momento da validação cruzada** (separar o dataset em conjunto de treino, validação e teste)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sun2R-xhn2G0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "caf05e1c-019d-4c07-ffb3-677d7d715683"
      },
      "source": [
        "# o sklearn, biblioteca que usaremos para construir o classificador de sentimentos não consegue realizar calculos\n",
        "# se tivermos features do tipo string. Portanto mudaremos os valores da feature alvo de 'pos' para 1 e 'neg' para 0\n",
        "\n",
        "target_encode = {'neg':0, 'pos': 1 }\n",
        "\n",
        "df.sentimento.replace(target_encode, inplace=True)\n",
        "\n",
        "df.sentimento.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    24765\n",
              "1    24694\n",
              "Name: sentimento, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsoHREhqn2G7"
      },
      "source": [
        "# salvar um novo arquivo .csv do dataset com o pré processamento aplicado acima\n",
        "df.to_csv('imdb-reviews-pt-br-modified.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm-K27UPn2HD"
      },
      "source": [
        "Conclusões de Pre Processing: Este pré processamento é realizado para que os dados estejam preparados para as técnicas de NLP que serão aplicadas "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNmxJloWn2HE"
      },
      "source": [
        "### Funções auxiliares a modelagem do classificador de sentimentos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZH9bcJnn2HF"
      },
      "source": [
        "# checar se o módulo nltk está instalado\n",
        "def check_module(module):\n",
        "    nltk.download(module)\n",
        "\n",
        "# configurar stopwords da biblioteca nltk para a lingua especificada\n",
        "def setup_nltk_stopwords(language, module):\n",
        "    check_module(module)   \n",
        "    return nltk.corpus.stopwords.words(language)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9X08ez5Dn2HK"
      },
      "source": [
        "# tokenização - necessário para aplicação de STEMMER usando a biblioteca nltk\n",
        "# esta biblioteca ao contrario do sklearn nao faz a tokenização automaticamente\n",
        "def tokenize(feature,module):\n",
        "    check_module(module)\n",
        "    data_frame = feature\n",
        "    return data_frame.apply(word_tokenize)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBmEr0X7n2HQ"
      },
      "source": [
        "# Contagem de termos com n-gramas usando o método CountVectorizer \n",
        "def count_term(ngram=None,words=None):\n",
        "    return CountVectorizer(ngram_range=ngram, stop_words=words)\n",
        "\n",
        "# TF-IDF\n",
        "def tf_idf(ngram=None, words=None, idf=False):\n",
        "    return TfidfVectorizer(ngram_range=ngram, use_idf=idf, stop_words=words)\n",
        "\n",
        "# treinar\n",
        "def vect_fit(feature, vect):\n",
        "    return vect.fit(feature)\n",
        "\n",
        "# transformar - para dataset de teste usar apenas vect_transform\n",
        "def vect_transform(feature, vect_fit):\n",
        "    return vect.transform(feature)    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnEOG441n2HW"
      },
      "source": [
        "# Stemmer\n",
        "def init_rslp():\n",
        "    check_module('rslp')\n",
        "    return RSLPStemmer()\n",
        "\n",
        "def stem_pandas(line):\n",
        "    return ' '.join([rslp.stem(token) for token in line])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBLGo12hn2Hb"
      },
      "source": [
        "# score básico (como é calculado?)\n",
        "def accuracy(y_test, y_pred):\n",
        "    return {'Acurácia: ': accuracy_score(y_test, y_pred)}\n",
        "\n",
        "# matriz de confusão\n",
        "def confusion(classifier, y_test, y_pred):\n",
        "    return {'Matriz de Confusão: ' : confusion_matrix(y_test, y_pred)}\n",
        "    \n",
        "# f1 score\n",
        "def f1(y_test, y_pred):\n",
        "    return {'F1 Score' : f1_score(y_test, y_pred)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kBhj4vun2Hh"
      },
      "source": [
        "# Classificador com modelo de Árvore de Decisão - DecisionTree \n",
        "descricao = 'descrição muito breve da configuração do modelo'\n",
        "score_dict = {}\n",
        "\n",
        "def decision_tree_classifier(X_train, y_train, X_test,y_test):\n",
        "       \n",
        "    classifier = DecisionTreeClassifier()\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    \n",
        "    score_ = accuracy(y_test, y_pred)\n",
        "    conf_ = confusion(classifier, y_test, y_pred)\n",
        "    f1_ = f1(y_test, y_pred)\n",
        "    \n",
        "    print('Árvore de Decisão')\n",
        "    print(score_)\n",
        "    print(conf_)\n",
        "    print(f1_)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpTjI7mBn2Hn"
      },
      "source": [
        "# modelo Regressão Logística\n",
        "def logistic_regression_classifier(X_train, y_train, X_test,y_test):\n",
        "       \n",
        "    classifier = LogisticRegression()\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    \n",
        "    score_ = accuracy(y_test, y_pred)\n",
        "    conf_ = confusion(classifier, y_test, y_pred)\n",
        "    f1_ = f1(y_test, y_pred)\n",
        "    \n",
        "    print('Regressão Logística')\n",
        "    print(score_)\n",
        "    print(conf_)\n",
        "    print(f1_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ0jtu1Yn2Hs"
      },
      "source": [
        "# modelo SVM\n",
        "def svm_classifier(X_train, y_train, X_test, y_test):\n",
        "    \n",
        "    classifier = svm.SVC()\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    \n",
        "    score_ = accuracy(y_test, y_pred)\n",
        "    conf_ = confusion(classifier, y_test, y_pred)\n",
        "    f1_ = f1(y_test, y_pred)\n",
        "    \n",
        "    print('SVM')\n",
        "    print(score_)\n",
        "    print(f1_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hAzSeuvn2Hw"
      },
      "source": [
        "# modelo naïve bayes\n",
        "def naive_bayes_classifier(X_train, y_train, X_test, y_test, alpha):\n",
        "    \n",
        "    classifier = MultinomialNB(alpha=alpha)\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    \n",
        "    score_ = accuracy(y_test, y_pred)\n",
        "    conf_ = confusion(classifier,  y_test, y_pred)\n",
        "    f1_ = f1(y_test, y_pred)\n",
        "    \n",
        "    print('Naïve Bayes')\n",
        "    print(score_)\n",
        "    print(f1_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lhIQQJ0n2H2"
      },
      "source": [
        "# separar dataset entre treino e teste\n",
        "def split_data(X, y, size):\n",
        "    return train_test_split(X, y, test_size=size)\n",
        "\n",
        "# quantidade de registros em cada dataset\n",
        "def return_shape(train, val, test):\n",
        "    return {'Train Shape': train.shape[0], \n",
        "            'Validation Shape': val.shape[0],\n",
        "            'Test Shape': test.shape[0]}\n",
        "\n",
        "# proporção de cada dataset (treino, validação e teste) em relação ao dataset completo\n",
        "def proportion_train_val_test(df, train, val, test):\n",
        "     \n",
        "    data_size = []\n",
        "    data_list = [train, val, test]\n",
        "    full_size = df.shape[0]\n",
        "    \n",
        "    for fraction in data_list:\n",
        "        data_size.append(fraction.shape[0]/full_size)        \n",
        "        \n",
        "    return {'Train Prop': data_size[0],\n",
        "            'Validation Prop' : data_size[1],\n",
        "            'Test Prop': data_size[2]}\n",
        "                       \n",
        "\n",
        "# proporção de respostas em cada dataset (treino, validação e teste)\n",
        "def strat_train_val_test(y_train, y_val, y_test):\n",
        "    target_strat = []\n",
        "    data_list = [y_train, y_val, y_test]\n",
        "    \n",
        "    for target in data_list:\n",
        "        target_strat.append(target.mean())\n",
        "    \n",
        "    \n",
        "    return {'Train Pos': target_strat[0],\n",
        "            'Validation Pos' : target_strat[1],\n",
        "            'Test Pos' : target_strat[2]}\n",
        "                         \n",
        "                         "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwNF0e1jn2H-"
      },
      "source": [
        "### Configurar semente de geração de números pseudo aleatórios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mffSlnSsn2H-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f703426-b4e8-41a8-c66d-df00246afc13"
      },
      "source": [
        "# obter seed atual do numpy\n",
        "np.random.get_state()[1][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2147483648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHwp4BExn2IF"
      },
      "source": [
        "# fixar semente (seed) para geração de números aleatórios.Com isso o default do scikit learn será o número\n",
        "# definido abaixo e não teremos a necessidade de configurar isso toda vez que algum método necessitar \n",
        "# deste parametro\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "assert np.random.get_state()[1][0] == SEED"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbPIGT8Wn2IM"
      },
      "source": [
        "### Configuração de validação cruzada\n",
        "\n",
        "Para testarmos nosso modelo usaremos primeiramente o dataset de validação, para ver como o modelo se comporta ao ser alimentado com novos dados. Após os experimentos será escolhido o modelo campeão, isto é o que possuir o maior F1 Score, e só então faremos a comparação do modelo utilizando o dataset de teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JujKCqJn2IN"
      },
      "source": [
        "# definição daproporção dos datasets de teste e validação em relação ao\n",
        "# dataset completo\n",
        "test_size = 0.20\n",
        "val_size = 0.20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZygVy7-tn2IS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2747b648-e3bd-49df-a2a7-367a41e631fc"
      },
      "source": [
        "# teste das funções definidas acima\n",
        "# para termos uma validação cruzada robusta, dividimos o dataset de treino\n",
        "# em um dataset de validação para que os modelos gerados sejam primeiro \n",
        "# conferidos em relação a esses dados de validação. Após o modelo campeão\n",
        "# ser escolhido\n",
        "X = df.texto_pt\n",
        "y = df.sentimento\n",
        "\n",
        "X_train, X_test, y_train, y_test = split_data(X,y, size = test_size)\n",
        "\n",
        "X_train, X_val, y_train, y_val = split_data(X_train, y_train, size=val_size)\n",
        "\n",
        "print(return_shape(X_train, X_val, X_test))\n",
        "print(proportion_train_val_test(df, X_train, X_val, X_test))\n",
        "print(strat_train_val_test(y_train, y_val, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Train Shape': 31653, 'Validation Shape': 7914, 'Test Shape': 9892}\n",
            "{'Train Prop': 0.6399846337370347, 'Validation Prop': 0.16001132250955336, 'Test Prop': 0.2000040437534119}\n",
            "{'Train Pos': 0.49830979685969734, 'Validation Pos': 0.4945665908516553, 'Test Pos': 0.5061665992721391}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXHGdVg2n2IX"
      },
      "source": [
        "Daqui para frente todas as técnicas de featuring engineering serão feitas no dataset de treino **X_train**, não podemos ter dados de validação no treino do modelo de classificação para que este não conheça de antemão os dados de validação e teste, o que é conhecido por **data leakage** e nos leve a um modelo que \"decora\" muito bem os dados do dataset de teste, se saindo mal quando novos valores são apresentados, evitando assim **overfitting** do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HscJzhMsn2IZ"
      },
      "source": [
        "### Modelo Baseline\n",
        "\n",
        "Nesta fase serão gerados dois modelos de classificação mais básicos possíveis com as seguintes características:\n",
        "\n",
        "- Serão gerados apenas **unigramas**\n",
        "\n",
        "- As 'stopwords' não serão retiradas dos texto da feature texto_pt\n",
        "\n",
        "- **Modelo Baseline 1:** usando o dataset de validação para teste do F1 Score do modelo\n",
        "\n",
        "- **Modelo Baseline 2:** usando um dataset com todos os valores igual 1 (avaliação positiva) para teste do F1 Score do modelo\n",
        "\n",
        "Um desses modelo será adotado como *baseline*, ou seja, seu valor de F1 Score será o mínimo que um modelo deve alcançar, quando comparado com outros modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JtUFGWqn2Ia",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "18b45f20-c66a-41ad-fbbd-48f509659ea7"
      },
      "source": [
        "# baseline model utilizando classificação por árvore de decisão\n",
        "\n",
        "# Pipeline de modelagem\n",
        "\n",
        "# usar unigramas\n",
        "n_gram=(1,1)\n",
        "\n",
        "# 1) Contagem de termos com unigrama sem retirar stopwords do texto\n",
        "vect = count_term(ngram=n_gram, words=None)\n",
        "fit = vect_fit(X_train, vect)\n",
        "vect_text = vect_transform(X_train, fit)\n",
        "\n",
        "# 2)transformar os dados de validação mantendo as regras usadas no  \n",
        "# dataset de treino\n",
        "val_text = vect_transform(X_val, fit)\n",
        "\n",
        "# 3) Treinar modelo - Árvore de decisão\n",
        "# 3.1) usando dataset de validação\n",
        "decision_tree_classifier(vect_text, y_train, val_text, y_val)\n",
        "\n",
        "# 3.2) todos os filmes classificados como positivo\n",
        "# qual acurácia e F1 score obtemos se todos os filmes forem classificados como positivo?\n",
        "y_baseline = np.ones(y_val.shape[0])\n",
        "decision_tree_classifier(vect_text, y_train, val_text, y_baseline)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Árvore de Decisão\n",
            "{'Acurácia: ': 0.6988880464998737}\n",
            "{'Matriz de Confusão: ': array([[2774, 1251],\n",
            "       [1132, 2757]])}\n",
            "{'F1 Score': 0.6982398379131316}\n",
            "Árvore de Decisão\n",
            "{'Acurácia: ': 0.4935557240333586}\n",
            "{'Matriz de Confusão: ': array([[   0,    0],\n",
            "       [4008, 3906]])}\n",
            "{'F1 Score': 0.6609137055837564}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jvb3Xq1Xn2Ih"
      },
      "source": [
        "### Conclusão Baseline\n",
        "\n",
        "Vamos adotar o modelo de classificação de árvore de decisão com **F1 Score de 69.82%** como nossa referência (baseline) ao avaliar os demais modelos gerados neste notebook.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3Dq8R-lsrIy"
      },
      "source": [
        "### Modelo 1) Contagem com unigramas sem retirar stopwords com modelo de Regressão Logística"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk0OVQEtn2Id",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "996b2ee2-6064-435e-ea73-400b4c35f475"
      },
      "source": [
        "# gerar modelo com a mesma configuração dos modelo anterior, com a diferença que \n",
        "# este é uma regressão logística\n",
        "logistic_regression_classifier(vect_text, y_train, val_text, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regressão Logística\n",
            "{'Acurácia: ': 0.8765478898155168}\n",
            "{'Matriz de Confusão: ': array([[3531,  494],\n",
            "       [ 483, 3406]])}\n",
            "{'F1 Score': 0.8745666966234433}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIUwRslIvfe6"
      },
      "source": [
        "Mantendo a mesma configuração, apenas alterando o tipo de modelo já obtemos uma melhora considerável no F1 Score da **regressão logística** = 87.45% em relação à **árvore de decisão** = 69.88%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJkRjTxNn2Ij"
      },
      "source": [
        "### Modelo 2) TF-IDF (unigrama com e sem stopwords) com modelos de Árvore de decisão, regresão logística, SVM.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqxpaIO0n2Im",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "61e39262-a522-45ce-c86b-17f11339898b"
      },
      "source": [
        "# configurar stopwords para a língua portuguesa e acrescentando '...' a estas\n",
        "# esses três pontos está presente em muitos textos deste nosso dataset \n",
        "stopwords = setup_nltk_stopwords('portuguese', 'stopwords') \n",
        "stopwords = stopwords + ['...']\n",
        "stopwords[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIDdRLvkn2Ir"
      },
      "source": [
        "# Pipeline\n",
        "# 1) TD-IDF com unigrama sem stopwords do texto\n",
        "n_gram = (1,1)\n",
        "vect = tf_idf(ngram=n_gram, words=stopwords, idf=True)\n",
        "#vect = tf_idf(ngram=n_gram, words=None, idf=True)\n",
        "fit = vect_fit(X_train, vect)\n",
        "vect_text = vect_transform(X_train, fit)\n",
        "\n",
        "# 2)transformar os dados de validação mantendo as regras usadas no  \n",
        "# dataset de treino\n",
        "val_text = vect_transform(X_val, fit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA3DhYKJn2Iw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d92c720c-1260-4ba8-e0fb-38b453ebb476"
      },
      "source": [
        "# 3) Treinar modelo\n",
        "# 3.1) Árvore de decisão com stopwords\n",
        "decision_tree_classifier(vect_text, y_train, val_text, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Árvore de Decisão\n",
            "{'Acurácia: ': 0.7016679302501896}\n",
            "{'Matriz de Confusão: ': array([[2828, 1172],\n",
            "       [1189, 2725]])}\n",
            "{'F1 Score': 0.6977339649212649}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GCLuEexn2I3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e8bccccf-521f-4dac-cdb2-91f9d9f6ddf9"
      },
      "source": [
        "# 3.2) Regressão Logística com stopwords \n",
        "logistic_regression_classifier(vect_text, y_train, val_text, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regressão Logística\n",
            "{'Acurácia: ': 0.8953752843062927}\n",
            "{'Matriz de Confusão: ': array([[3537,  463],\n",
            "       [ 365, 3549]])}\n",
            "{'F1 Score': 0.8955336866010597}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvri9LfKn2I9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "186001fa-b2cd-4236-dff0-3b2d16c374c4"
      },
      "source": [
        "# 3.3) Regressão Logística sem stopwords (nltk)\n",
        "logistic_regression_classifier(vect_text, y_train, val_text, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regressão Logística\n",
            "{'Acurácia: ': 0.8952489259540055}\n",
            "{'Matriz de Confusão: ': array([[3536,  464],\n",
            "       [ 365, 3549]])}\n",
            "{'F1 Score': 0.8954207140153905}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpClfY6_n2JA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4676276a-3482-4cf6-9506-b112cea86c83"
      },
      "source": [
        "# 3.4) SVM com stopwords ngram=1,1 \n",
        "svm_classifier(vect_text, y_train, val_text, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM\n",
            "{'Acurácia: ': 0.9020722769775082}\n",
            "{'F1 Score': 0.9022082018927444}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE6P0F93YDrJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a58b24f6-ade6-4a5e-c5d2-b85f55273b71"
      },
      "source": [
        "# 3.5) SVM sem stopwords \n",
        "svm_classifier(vect_text, y_train, val_text, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM\n",
            "{'Acurácia: ': 0.9013141268637856}\n",
            "{'F1 Score': 0.9013016555036016}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d-pfMian2JR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cf06bb31-ba30-43c4-8bfb-7c747d0b7663"
      },
      "source": [
        "# 3.6) Naive Bayes\n",
        "naive_bayes_classifier(vect_text, y_train, val_text, y_val, alpha=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naïve Bayes\n",
            "{'Acurácia: ': 0.8685873136214304}\n",
            "{'F1 Score': 0.8646538261322229}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcaUXmYvn2JZ"
      },
      "source": [
        "### Conclusão CounterVectorize e TF-IDF\n",
        "\n",
        "Com stopwords e unigramas:\n",
        "\n",
        "- Arvore de Decisão: 70.16%\n",
        "- Regressão Logística: 89.55%\n",
        "- SVM: 90.22%\n",
        "- Naïve Bayes: 86.46%\n",
        "\n",
        "Sem stopwords (nltk) e unigramas:\n",
        "- Regressão Logística: 89.54%\n",
        "- SVM: 90.13%\n",
        "- Naïve Bayes: 86.17%\n",
        "\n",
        "Os modelos de Regressão Logistica e SVM sem retirar as stopwords do texto são os que se saíram melhor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAzdM2Ldn2Jb"
      },
      "source": [
        "### Modelo 3) Stemmer com unigrama"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MB7qm9nn2Jg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7017a464-1b95-4f21-f17b-d7b4d98f24b0"
      },
      "source": [
        "check_module('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Kn-s9SSn2Jw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c6e1f8c0-91c5-4c4a-e018-8062f1676131"
      },
      "source": [
        "# transformar os dados de treino em numpy array\n",
        "train = np.array(X_train)\n",
        "train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sim e. na verdade, e em algum lugar no meu top 20 filmes favoritos de todos os tempos. numero 15, eu acho. de qualquer forma, eu geralmente nao sou de planos, mas acho que os enredos funcionam melhor em jogos de anime e rpg, final fantasy 7, por exemplo, e nao em filmes. mas este tem tudo. desenhos vividos de planetas, estrelas, um roteiro extremamente bem escrito. enquanto isso nao e realmente para criancas, eles ainda podem assistir, nao contem sangue, coragem e silicone. mas eu nao acho que eles vao entender isso.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwkepQ7On2KA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "8bbe98abb34a44a29e1c60e5c2b1df0b",
            "7cb7682a9a5f4dbfafa71c1663d1b4fd",
            "c225b28fb2534b9982bcc27dae05f3c3",
            "6bb1865c42e543609c718e53761c1fb3",
            "149a6d49306945ada75144067d180d61",
            "1a5cbc54edf94e279a16e0914f92924e",
            "0b0928cec3fd47d8a80d8b780184103b",
            "5fc0122ec9904bd58128f218e4a1f237"
          ]
        },
        "outputId": "be62f72d-757d-485a-ecbf-7c03270df917"
      },
      "source": [
        "# tokenizar os textos do dataset de treino\n",
        "token_list = []\n",
        "for text in tqdm(train):\n",
        "    token_list.append(word_tokenize(text))  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bbe98abb34a44a29e1c60e5c2b1df0b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=31653.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFCk95oxn2KE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80351ef8-cfa3-47f8-9e8d-92987bf39dc3"
      },
      "source": [
        "# visualizar tokenização de um texto\n",
        "token_list[5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['este',\n",
              " 'filme',\n",
              " 'nao',\n",
              " 'e',\n",
              " 'realmente',\n",
              " 'um',\n",
              " 'remake',\n",
              " 'do',\n",
              " 'filme',\n",
              " 'de',\n",
              " '1949',\n",
              " 'obrien',\n",
              " 'que',\n",
              " 'e',\n",
              " 'excelente',\n",
              " '.',\n",
              " 'ele',\n",
              " 'empresta',\n",
              " 'a',\n",
              " 'premissa',\n",
              " 'principal',\n",
              " '-',\n",
              " 'um',\n",
              " 'homem',\n",
              " 'foi',\n",
              " 'envenenado',\n",
              " 'e',\n",
              " 'passa',\n",
              " 'o',\n",
              " 'resto',\n",
              " 'do',\n",
              " 'filme',\n",
              " 'tentando',\n",
              " 'encontrar',\n",
              " 'seu',\n",
              " 'assassino',\n",
              " '.',\n",
              " 'mas',\n",
              " 'eu',\n",
              " 'gosto',\n",
              " 'que',\n",
              " 'os',\n",
              " 'escritores',\n",
              " 'escolheram',\n",
              " 'um',\n",
              " 'professor',\n",
              " 'de',\n",
              " 'ingles',\n",
              " ',',\n",
              " 'em',\n",
              " 'vez',\n",
              " 'de',\n",
              " 'um',\n",
              " 'penis',\n",
              " 'particular',\n",
              " ',',\n",
              " 'como',\n",
              " 'protagonista',\n",
              " '.',\n",
              " 'o',\n",
              " 'enredo',\n",
              " 'tambem',\n",
              " 'e',\n",
              " 'bastante',\n",
              " 'original',\n",
              " '.',\n",
              " 'em',\n",
              " 'geral',\n",
              " ',',\n",
              " 'o',\n",
              " 'filme',\n",
              " 'se',\n",
              " 'move',\n",
              " 'rapido',\n",
              " 'o',\n",
              " 'suficiente',\n",
              " 'para',\n",
              " 'mante-lo',\n",
              " 'acordado',\n",
              " '.',\n",
              " 'mas',\n",
              " 'o',\n",
              " 'que',\n",
              " 'estraga',\n",
              " 'este',\n",
              " 'filme',\n",
              " 'e',\n",
              " 'uma',\n",
              " 'qualidade',\n",
              " 'estranha',\n",
              " 'datada',\n",
              " 'sobre',\n",
              " 'ele',\n",
              " 'provavelmente',\n",
              " 'devido',\n",
              " 'a',\n",
              " 'horrenda',\n",
              " 'musica',\n",
              " 'original',\n",
              " 'dos',\n",
              " 'anos',\n",
              " '80',\n",
              " 'scorecombined',\n",
              " 'com',\n",
              " 'uma',\n",
              " 'sensacao',\n",
              " '``',\n",
              " 'noir',\n",
              " \"''\",\n",
              " 'afetada',\n",
              " '.',\n",
              " 'dennis',\n",
              " 'quaid',\n",
              " 'sorri',\n",
              " 'inexplicavelmente',\n",
              " 'durante',\n",
              " 'todo',\n",
              " 'o',\n",
              " 'filme',\n",
              " 'em',\n",
              " 'momentos',\n",
              " 'estranhos',\n",
              " ',',\n",
              " 'mas',\n",
              " 'ainda',\n",
              " 'e',\n",
              " 'convincente',\n",
              " 'de',\n",
              " 'um',\n",
              " 'modo',\n",
              " 'geral',\n",
              " '.',\n",
              " 'meg',\n",
              " 'ryan',\n",
              " 'esta',\n",
              " 'bem',\n",
              " 'como',\n",
              " 'o',\n",
              " 'interesse',\n",
              " 'de',\n",
              " 'estudante',\n",
              " 'ajudante',\n",
              " '/',\n",
              " 'amor',\n",
              " '.',\n",
              " 'quando',\n",
              " 'o',\n",
              " 'filme',\n",
              " 'fica',\n",
              " 'meio',\n",
              " 'ruim',\n",
              " 'e',\n",
              " 'quando',\n",
              " 'dex',\n",
              " 'o',\n",
              " 'professor',\n",
              " 'encontra',\n",
              " 'o',\n",
              " 'guarda-costas',\n",
              " '/',\n",
              " 'motorista',\n",
              " 'britanico',\n",
              " 'e',\n",
              " 'seus',\n",
              " 'duelos',\n",
              " 'sao',\n",
              " 'bem',\n",
              " 'risiveis',\n",
              " '.',\n",
              " 'o',\n",
              " 'guarda-costas',\n",
              " 'trabalha',\n",
              " 'para',\n",
              " 'a',\n",
              " 'rica',\n",
              " 'viuva',\n",
              " 'interpretada',\n",
              " 'pela',\n",
              " 'adoravel',\n",
              " 'charlotte',\n",
              " 'rampling',\n",
              " ',',\n",
              " 'mas',\n",
              " 'essas',\n",
              " 'cenas',\n",
              " 'sao',\n",
              " '``',\n",
              " 'noir',\n",
              " \"''\",\n",
              " 'muito',\n",
              " 'autoconscientes',\n",
              " 'para',\n",
              " 'ajudar',\n",
              " 'o',\n",
              " 'filme',\n",
              " ',',\n",
              " 'embora',\n",
              " 'a',\n",
              " '``',\n",
              " 'trama',\n",
              " \"''\",\n",
              " 'familiar',\n",
              " 'seja',\n",
              " 'bastante',\n",
              " 'interessante',\n",
              " '.',\n",
              " 'dex',\n",
              " 'tambem',\n",
              " 'continua',\n",
              " 'aparecendo',\n",
              " 'no',\n",
              " 'mesmo',\n",
              " 'lugar',\n",
              " 'e',\n",
              " 'encontrando',\n",
              " 'este',\n",
              " 'guarda-costas',\n",
              " ',',\n",
              " 'o',\n",
              " 'que',\n",
              " 'e',\n",
              " 'bastante',\n",
              " 'coincidente',\n",
              " '.',\n",
              " 'na',\n",
              " 'ultima',\n",
              " 'parte',\n",
              " 'do',\n",
              " 'filme',\n",
              " ',',\n",
              " 'um',\n",
              " 'homem',\n",
              " 'e',\n",
              " 'baleado',\n",
              " 'por',\n",
              " 'uma',\n",
              " 'janela',\n",
              " 'e',\n",
              " ',',\n",
              " 'do',\n",
              " 'lado',\n",
              " 'de',\n",
              " 'fora',\n",
              " ',',\n",
              " 'voce',\n",
              " 'o',\n",
              " 've',\n",
              " 'saltar',\n",
              " 'fora',\n",
              " '-',\n",
              " 'isso',\n",
              " 'era',\n",
              " 'uma',\n",
              " 'direcao',\n",
              " 'muito',\n",
              " 'ruim',\n",
              " '.',\n",
              " 'mas',\n",
              " ',',\n",
              " 'alem',\n",
              " 'de',\n",
              " 'algumas',\n",
              " 'dessas',\n",
              " 'falhas',\n",
              " 'obvias',\n",
              " ',',\n",
              " 'acho',\n",
              " 'que',\n",
              " 'ainda',\n",
              " 'e',\n",
              " 'valido',\n",
              " '.',\n",
              " 'eu',\n",
              " 'certamente',\n",
              " 'nao',\n",
              " 'previ',\n",
              " 'o',\n",
              " 'final',\n",
              " ',',\n",
              " 'entao',\n",
              " 'isso',\n",
              " 'foi',\n",
              " 'bom',\n",
              " '-',\n",
              " 'ha',\n",
              " 'uma',\n",
              " 'reviravolta',\n",
              " ',',\n",
              " 'e',\n",
              " 'embora',\n",
              " 'alguns',\n",
              " 'posteres',\n",
              " 'aqui',\n",
              " 'achem',\n",
              " 'que',\n",
              " 'foram',\n",
              " 'enganados',\n",
              " ',',\n",
              " 'eu',\n",
              " 'pensei',\n",
              " 'que',\n",
              " 'era',\n",
              " 'um',\n",
              " 'final',\n",
              " 'bom',\n",
              " 'e',\n",
              " 'crivel',\n",
              " '.',\n",
              " 'dennis',\n",
              " 'quaid',\n",
              " ',',\n",
              " 'com',\n",
              " 'seus',\n",
              " 'estranhos',\n",
              " 'sorrisos',\n",
              " 'e',\n",
              " 'olhos',\n",
              " 'negros',\n",
              " ',',\n",
              " 'e',\n",
              " 'mais',\n",
              " 'simpatico',\n",
              " 'em',\n",
              " 'the',\n",
              " 'right',\n",
              " 'stuff',\n",
              " ',',\n",
              " 'great',\n",
              " 'balls',\n",
              " 'of',\n",
              " 'fire',\n",
              " ',',\n",
              " 'inner',\n",
              " 'space',\n",
              " 'e',\n",
              " 'cold',\n",
              " 'creek',\n",
              " 'manor',\n",
              " '.',\n",
              " 'mas',\n",
              " 'aqui',\n",
              " 'como',\n",
              " 'dex',\n",
              " ',',\n",
              " 'ele',\n",
              " 'deveria',\n",
              " 'ser',\n",
              " 'um',\n",
              " 'idiota',\n",
              " ',',\n",
              " 'entao',\n",
              " 'ele',\n",
              " 'se',\n",
              " 'saiu',\n",
              " 'bem',\n",
              " '.',\n",
              " 'filme',\n",
              " 'bastante',\n",
              " 'decente',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clxDGtZ8n2KM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcc13020-e20f-4469-d65a-d0327fbdb8ca"
      },
      "source": [
        "# transformar a lista dos textos tokenizados em numpy array\n",
        "np_token_list = np.array(token_list)\n",
        "np_token_list.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31653,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puIwXf61n2KR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151,
          "referenced_widgets": [
            "12a70cdd51324d43bcf2abf9f6f78652",
            "1115c3e7b5e54b8c97d7f7703bfba70f",
            "4d9a2fd2319f41f192c46d1c7c68b234",
            "dc35bba90f5b4e48992996ea3ea180f4",
            "7a59366db06f4e1496ecae9c1ae3ffa7",
            "6b7942268376414fa83309e773be2942",
            "9d998cc5dd994bcb9564734732241af9",
            "ce719b449b124927842c174bba518988"
          ]
        },
        "outputId": "5f91ab1c-1617-4403-c645-f944cd98f5ba"
      },
      "source": [
        "# fazer o stemmatização do texto (pegar a raiz das palavras dos textos)\n",
        "rslp = init_rslp()\n",
        "\n",
        "stemmer_list = []\n",
        "for token in tqdm(np_token_list):\n",
        "    stemmer_list.append(stem_pandas(token))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12a70cdd51324d43bcf2abf9f6f78652",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=31653.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjrFnhD1n2KV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "95987b52-eabb-478e-edd7-ec77326c29cd"
      },
      "source": [
        "# visualizar a stemmatização de um texto do dataset\n",
        "stemmer_list[7]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"hom alon 3 e o prim do film hom alon a nao apresent culkin no papel princip e no mesm vilo . no entant , o enred e muit semelh ao film orig de hom alon . em vez de doi vilo comic , tem tre ou quatr del . est film envolv algum armadilh , mas tamb tem uma cen long com um carr de control remot . o hum pastela tamb e consist , mas o menin e os vilo real nao conseg caus impact ness film . nenhum trocadilh intenc . est film nao oferec nad de nov ou difer do que os film anteri fiz , e real nao ha o clim quent de fim de ano ou as subtram que os outr doi film tiv . e mais uma comed pur , mas nao consegu me faz rir , ja que os person real nao fiz iss por mim . eu nao recomend ess film ; e muit chat . se voc est procur um bom film famili com comed , enta assist ao film orig `` hom alon '' .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHtW8xc3n2KZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3a0f21e-0454-4825-f9ef-c98a9cdbf869"
      },
      "source": [
        "# transformar a lista dos textos stemmatizados em numpy array para entrada nas\n",
        "# técnicas de TF-IDF\n",
        "np_stemmer_list = np.array(stemmer_list)\n",
        "np_stemmer_list.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31653,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wl44WuTn2Kd"
      },
      "source": [
        "# Pipeline \n",
        "# TF-IDF\n",
        "n_gram =(1,1)\n",
        "#vect = tf_idf(ngram=n_gram, words=stopwords, idf=True)\n",
        "vect = tf_idf(ngram=n_gram, words=None, idf=True)\n",
        "fit = vect_fit(np_stemmer_list, vect)\n",
        "vect_text = vect_transform(np_stemmer_list, fit)\n",
        "\n",
        "val_text = vect_transform(X_val, fit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqPo2RwDn2K-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "86fe49a8-dc68-4b55-f85c-fc4227b28e2e"
      },
      "source": [
        "# modelo de árvore de decisao\n",
        "decision_tree_classifier(vect_text, y_train, val_text, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Árvore de Decisão\n",
            "{'Acurácia: ': 0.5875663381349507}\n",
            "{'Matriz de Confusão: ': array([[1071, 2929],\n",
            "       [ 335, 3579]])}\n",
            "{'F1 Score': 0.6868163500287853}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_45FdIRn2LD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "5352231c-f13c-4fea-d66e-1781bcfedaff"
      },
      "source": [
        "# modelo de regressão logistica\n",
        "logistic_regression_classifier(vect_text, y_train, val_text, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regressão Logística\n",
            "{'Acurácia: ': 0.7505686125852918}\n",
            "{'Matriz de Confusão: ': array([[2628, 1372],\n",
            "       [ 602, 3312]])}\n",
            "{'F1 Score': 0.7704117236566642}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZioAKkl0KTK"
      },
      "source": [
        "### Conclusão Stemmer\n",
        "\n",
        "Nenhum dos modelos gerados após stemmatização teve um bom desempenho comparando com os modelos gerados utilizando apenas TF-IDF sem stemmatizar.\n",
        "\n",
        "O modelo de árvore de decisão teve F1 Score de 68.68%, **inferior ao F1 Score baseline**, que é de 69.88%. O modelo de regressão logística também ficou bem abaixo do melhor modelo gerado usando esta técnica de machine learning com F1 Score de 77.04%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq4ld0ENn2LX"
      },
      "source": [
        "### Modelo 4) Lemmer\n",
        "\n",
        "- uso da biblioteca spacy, ja que a nltk não possui pos tagger para a lingua portuguesa\n",
        "- comparação da quantidade de stopwords do nltk e spacy\n",
        "- uso das stopwords das duas bibliotecas combinadas "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urtbx2HQn2LY"
      },
      "source": [
        "# associar uma nova variável para manipular o dataset de treino\n",
        "train = X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIkiqGrSn2Lb"
      },
      "source": [
        "counter = Counter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xSuO4Rx6pnO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3635374b-6637-4605-87fe-e740526c1751"
      },
      "source": [
        "# instalar corpus de lingua portuguesa da biblioteca spacy\n",
        "!python -m spacy download pt_core_news_sm\n",
        "!python -m spacy download pt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pt_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz (21.2MB)\n",
            "\u001b[K     |████████████████████████████████| 21.2MB 864kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (46.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.18.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: pt-core-news-sm\n",
            "  Building wheel for pt-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pt-core-news-sm: filename=pt_core_news_sm-2.2.5-cp36-none-any.whl size=21186282 sha256=850161589e45d5b5ae5a72d5497d19319cdae4dc76dacb5a289969adc7d0cc5c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xu4qu84z/wheels/ea/94/74/ec9be8418e9231b471be5dc7e1b45dd670019a376a6b5bc1c0\n",
            "Successfully built pt-core-news-sm\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n",
            "Requirement already satisfied: pt_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz#egg=pt_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (46.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.18.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/pt\n",
            "You can now load the model via spacy.load('pt')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vt8iNtOY6wpt"
      },
      "source": [
        "# carregar corpus de stopwords do spacy (transformar em função)\n",
        "nlp = spacy.load('pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "LKyMrGkSn2Lg",
        "colab": {
          "referenced_widgets": [
            "e7e16ceb395248658d85c90b7c4e34ae"
          ]
        },
        "outputId": "20c4dae2-3be3-43d4-ffd7-c32fd12b65b5"
      },
      "source": [
        "# juntar todos os tags de cada texto do dataset de treino \n",
        "# comando demorado para rodar (quase 33 minutos)\n",
        "lista_pos = []\n",
        "\n",
        "for text in tqdm(train):\n",
        "    # documento do text0\n",
        "    doc = nlp(text)\n",
        "    # obter o pos tag do documento - vai pegar de todos os textos do dataset\n",
        "    for token in doc:\n",
        "        lista_pos.append(token.pos_)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/daniel/.local/lib/python3.7/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7e16ceb395248658d85c90b7c4e34ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=34052.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5xe3Tpmn2Li",
        "outputId": "a53f5d09-2988-4e80-f05b-08743fcea9da"
      },
      "source": [
        "# amostra da lista obtida no comando acima\n",
        "lista_pos[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['DET', 'NOUN', 'CCONJ', 'DET', 'NOUN', 'VERB', 'NOUN', 'ADP', 'NOUN', 'PUNCT']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4tsipK0n2Ll"
      },
      "source": [
        "# contar o pos tag de todo o texto\n",
        "for pos in lista_pos:\n",
        "    counter[pos] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7EnfGfHn2Ln",
        "outputId": "92cc10bb-9d6b-4a3e-ec35-6d37e4371a31"
      },
      "source": [
        "counter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'DET': 1018423,\n",
              "         'NOUN': 1432693,\n",
              "         'CCONJ': 385947,\n",
              "         'VERB': 1080735,\n",
              "         'ADP': 921651,\n",
              "         'PUNCT': 1053644,\n",
              "         'PROPN': 665772,\n",
              "         'ADJ': 515421,\n",
              "         'NUM': 75667,\n",
              "         'SYM': 89821,\n",
              "         'ADV': 448996,\n",
              "         'SCONJ': 156069,\n",
              "         'PRON': 521800,\n",
              "         'AUX': 156349,\n",
              "         'X': 24474,\n",
              "         'SPACE': 2984,\n",
              "         'INTJ': 1144,\n",
              "         'PART': 211})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSXp6L2nn2Lq",
        "outputId": "d5248167-c3b8-4024-e245-7aad1fe4105d"
      },
      "source": [
        "# transformar em dataframe\n",
        "pos_tag = pd.DataFrame(data=counter.items(), columns=['Tag', 'Count']).sort_values(by='Count', ascending=False).reset_index()\n",
        "pos_tag.drop(labels='index', axis=1, inplace=True)\n",
        "pos_tag"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tag</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NOUN</td>\n",
              "      <td>1432693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>VERB</td>\n",
              "      <td>1080735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PUNCT</td>\n",
              "      <td>1053644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DET</td>\n",
              "      <td>1018423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ADP</td>\n",
              "      <td>921651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>PROPN</td>\n",
              "      <td>665772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>PRON</td>\n",
              "      <td>521800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ADJ</td>\n",
              "      <td>515421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ADV</td>\n",
              "      <td>448996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CCONJ</td>\n",
              "      <td>385947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>AUX</td>\n",
              "      <td>156349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>SCONJ</td>\n",
              "      <td>156069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>SYM</td>\n",
              "      <td>89821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NUM</td>\n",
              "      <td>75667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>X</td>\n",
              "      <td>24474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>SPACE</td>\n",
              "      <td>2984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>1144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>PART</td>\n",
              "      <td>211</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Tag    Count\n",
              "0    NOUN  1432693\n",
              "1    VERB  1080735\n",
              "2   PUNCT  1053644\n",
              "3     DET  1018423\n",
              "4     ADP   921651\n",
              "5   PROPN   665772\n",
              "6    PRON   521800\n",
              "7     ADJ   515421\n",
              "8     ADV   448996\n",
              "9   CCONJ   385947\n",
              "10    AUX   156349\n",
              "11  SCONJ   156069\n",
              "12    SYM    89821\n",
              "13    NUM    75667\n",
              "14      X    24474\n",
              "15  SPACE     2984\n",
              "16   INTJ     1144\n",
              "17   PART      211"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k8XNhsvn2Lu"
      },
      "source": [
        "# salvar o postag em arquivo csv\n",
        "pos_tag.to_csv('postag_filmes.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzEasNQ2n2Lx"
      },
      "source": [
        "O que siginificado de cada símbolo da lista de pos tag acima pode ser encontrada no link: https://spacy.io/api/annotation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BepAwMNBn2MO"
      },
      "source": [
        "# função para lemmatizar todo o texto \n",
        "def lemmatizer_text(text):\n",
        "    sent = []\n",
        "    doc = nlp(text)\n",
        "    for word in doc:\n",
        "        sent.append(word.lemma_)\n",
        "    return \" \".join(sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL34sEkln2MS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4a752a43-e902-4451-e906-c11b82e577bf"
      },
      "source": [
        "lemmatizer_text(train[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'este e um exemplo do motivar pelar qual o maioria dos filme de acao sao o mesmo . generico e chato , nao ha nado que valer o peno assistir aqui . um completar desperdicio dos talento de ice-t e cubar de gelar que ser mal aproveitar , cada um comprovar que sao capaz de atuar e agir bem . nao se incomodar com este , va ver new jack city , ricochet ou assistir new york undercover parir ice-t , ou boyz o hood , higher learning ou friday ser içar cubar e ver o negociar real . ice-ts horrivelmente cliche dialogar só fazer este filmar ralar o dente , e eu ainda estar me perguntar o que diabo bill paxton estar fazer n este filmar ? e por que diabo ele sempre interpretar exatamente o mesmo personagem ? dos extraterrestre em diante , todo o filme que eu vir com bill paxton o fazer interpretar exatamente o mesmo personagem irritante , e pelar menos em aliens seu personagem morrer , o que o tornar um pouco gratificante ... o geral , esse e lixar de acao de segundo classe . existir incontaveis    filme melhorar parir ver , e se voce realmente querer ver esse filmar , assistir o judgment night , que e praticamente umar copiar carbono , mas ter melhor atuacao e um roteiro melhor . o unica coisa que fazer isso valer o peno assistir ser umar mao decente o camera - o cinematografia ser quase refrescante , o que chegar perto de compensar o horrivel filmar em si - mas nao e bem assim . 4/10'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euO64C_4n2MV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "ffd4d96031d34928af97fc1c05946131",
            "e88a805b65a6479ab261ab5ecde59d95",
            "076fad26c38744ba900fdca9d544d350",
            "5fe4864321a047249be990d39ca50af5",
            "271a6c13ff6646bc85727b3e758d933e",
            "92033cd90cfb4989ab5ff0de38233251",
            "e8ebbbd75ec5450cbd6e83160a167ffa",
            "5723534749c24f63a4fc15a3e28c5328"
          ]
        },
        "outputId": "40a22918-97c4-4d7c-b41c-b7864ce3e6ee"
      },
      "source": [
        "# lemmatização de todos os textos do dataset de treino - processo leva meia hora\n",
        "# para processar\n",
        "lemmatized_text = []\n",
        "\n",
        "for text in tqdm(train):\n",
        "    lemmatized_text.append(lemmatizer_text(text))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ffd4d96031d34928af97fc1c05946131",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=31653.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8M9TT-ZZn2MY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "71fda176-eddf-4a32-eae1-67371868d52c"
      },
      "source": [
        "lemmatized_text[7]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'home alone 3 e o primeiro dos filme home alone o nao apresentar culkin o papel principal e o mesmo viloes . o entanto , o enredar e muito semelhante o o filmar original de home alone . em vez de dois viloes comicos , ter tres ou quatro d ele . este filmar envolver algum armadilhar , mas tambem ter umar cena longo com um carro de controlo remoto . o humor pastelao tambem e consistente , mas o menino e o viloes realmente nao conseguir causar impactar n esse filmar . nenhum trocadilhar intencional . este filmar nao oferecer nado de novo ou diferente do que o filme anterior fazer , e realmente nao ha o clima quentar de fim de ano ou o subtramas que o outro dois filme ter . e mais umar comedir puro , mas nao conseguir me fazer rir , ja que o personagem realmente nao fazer isso por mim . eu nao recomendar esse filmar ; e muito chato . se voce este procurar um bom filmar familiar com comedir , entao assistir o o filmar original \" home alone \" .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14nHLhXUn2Mb"
      },
      "source": [
        "# colocar o array lemmatizado em um dataframe\n",
        "texto = pd.DataFrame(lemmatized_text, columns=['texto_lemmatizado'])\n",
        "# salvar dataset lemmatizado em arquivo csv\n",
        "texto.to_csv('X_train_lemmatized.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV1zdFA9n2Me"
      },
      "source": [
        "# transformar o texto lemmatizado em np.array\n",
        "lemmatized_text = np.array(lemmatized_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CldHbKKEn2Mi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "4b2b6309-1a56-4fb4-bea4-24f841949f79"
      },
      "source": [
        "# countvectorizer nas features de lemmatização e modelo\n",
        "# Pipeline de modelagem\n",
        "\n",
        "# usar unigramas\n",
        "n_gram=(1,1)\n",
        "\n",
        "# 1) Contagem de termos com unigrama sem retirar stopwords do texto\n",
        "vect = count_term(ngram=n_gram, words=None)\n",
        "fit = vect_fit(lemmatized_text, vect)\n",
        "vect_text = vect_transform(lemmatized_text, fit)\n",
        "\n",
        "\n",
        "# 2)transformar os dados de validação mantendo as regras usadas no  \n",
        "# dataset de treino\n",
        "val_text = vect_transform(X_val, fit)\n",
        "\n",
        "# 3) Treinar modelo  \n",
        "# 3.1) Árvore de decisão\n",
        "decision_tree_classifier(vect_text, y_train, val_text, y_val)\n",
        "\n",
        "# 3.2) Regressão Logística\n",
        "logistic_regression_classifier(vect_text, y_train, val_text, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Árvore de Decisão\n",
            "{'Acurácia: ': 0.6702047005307051}\n",
            "{'Matriz de Confusão: ': array([[2499, 1501],\n",
            "       [1109, 2805]])}\n",
            "{'F1 Score': 0.6824817518248175}\n",
            "Regressão Logística\n",
            "{'Acurácia: ': 0.8217083649229214}\n",
            "{'Matriz de Confusão: ': array([[2928, 1072],\n",
            "       [ 339, 3575]])}\n",
            "{'F1 Score': 0.8351828057469922}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSmJ89fmn2Ml",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "901898ce-aa46-414f-c488-b80924915014"
      },
      "source": [
        "# TF-IDF nas features lemmatizadas e modelo\n",
        "# Pipeline\n",
        "# 1) TD-IDF com unigrama sem retirar stopwords do texto\n",
        "n_gram = (1,1)\n",
        "\n",
        "vect = tf_idf(ngram=n_gram, words=stopwords, idf=True)\n",
        "#vect = tf_idf(ngram=n_gram, words=None, idf=True)\n",
        "fit = vect_fit(lemmatized_text, vect)\n",
        "vect_text = vect_transform(lemmatized_text, fit)\n",
        "\n",
        "# 2)transformar os dados de validação mantendo as regras usadas no  \n",
        "# dataset de treino\n",
        "val_text = vect_transform(X_val, fit)\n",
        "\n",
        "# 3) Treinar modelo \n",
        "# 3.1) Árvore de decisão\n",
        "decision_tree_classifier(vect_text, y_train, val_text, y_val)\n",
        "\n",
        "# 3.2) Regressão Logística\n",
        "logistic_regression_classifier(vect_text, y_train, val_text, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Árvore de Decisão\n",
            "{'Acurácia: ': 0.6820823856456911}\n",
            "{'Matriz de Confusão: ': array([[2614, 1386],\n",
            "       [1130, 2784]])}\n",
            "{'F1 Score': 0.6887679366650173}\n",
            "Regressão Logística\n",
            "{'Acurácia: ': 0.8569623452110184}\n",
            "{'Matriz de Confusão: ': array([[3173,  827],\n",
            "       [ 305, 3609]])}\n",
            "{'F1 Score': 0.8644311377245509}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "483CkFxpCKZ1"
      },
      "source": [
        "### Conclusão Lemmer\n",
        "Sem retirar as stopwords do texto após lemmatizar tivemos um F1 Score de 69.92% no modelo de árvore de decisão e 85% no modelo de regressão logística. Após retirar as stopwords (corpus nltk) o modelo de árvore de decisão foi ainda pior com F1 Score de 68.20% enquanto a regressão logística se manteve próxima com 85.69%. Nenhum desses modelos melhorou o F1 Score obtido mais acima com TF-IDF sem retirar as stopwords do texto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL1ZE2ISn2LR"
      },
      "source": [
        "### Melhores modelos: Regressão logistica e SVM aplicando a técnica de **TF-IDF** e Unigrama **sem retirar** stopwords do texto\n",
        "\n",
        "Hora da verdade: o F1 Score dos dois modelos citados acima foram os mais altos e relativamente próximos, portando selecionamos os dois para uma disputa final conferindo o F1 Score rodando todo o pipeline de transformação de cada um novamente, porém, ao invés de usar o dataset de validação usaremos agora o dataset de teste (como se fosse uma submissão no Kaggle). Ja sabemos que o modelo SVM leva muito tempo para rodar, enquanto a regressão logística é rápida, porém para a seleção do modelo final para este estudo o que será levado em consideração será de fato o F1 Score. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klFmw_OTn2LS"
      },
      "source": [
        "# Pipeline - dataset de teste\n",
        "# 1) TD-IDF com unigrama retirarando stopwords do texto\n",
        "n_gram = (1,1)\n",
        "vect = tf_idf(ngram=n_gram, words=None, idf=True)\n",
        "fit = vect_fit(X_train, vect)\n",
        "vect_text = vect_transform(X_train, fit)\n",
        "\n",
        "# 2)transformar os dados de validação mantendo as regras usadas no  \n",
        "# dataset de treino\n",
        "test_text = vect_transform(X_test, fit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ6DvvWhaUp1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8489abad-ad52-47a0-a1bd-e7c27d029751"
      },
      "source": [
        "# 3) Regressao logistica com os dados de teste\n",
        "logistic_regression_classifier(vect_text, y_train, test_text, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Regressão Logística\n",
            "{'Acurácia: ': 0.8807116862110796}\n",
            "{'Matriz de Confusão: ': array([[4233,  652],\n",
            "       [ 528, 4479]])}\n",
            "{'F1 Score': 0.8836062339711975}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL-seHkFacXp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9fd8ac38-a7cc-497a-d198-4776ae553bc0"
      },
      "source": [
        "# 4) SVM com os dados de test \n",
        "svm_classifier(vect_text, y_train, test_text, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM\n",
            "{'Acurácia: ': 0.887484836231298}\n",
            "{'F1 Score': 0.8905281794039539}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYum_yRfa4-g"
      },
      "source": [
        "### Conclusão final:\n",
        "\n",
        "O vencedor foi o modelo SVM com F1 Score de 89.05%. Este é o modelo em que deveremos fazer o deploy e colocar em produção."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-ooNW65n2Mr"
      },
      "source": [
        "### Apêndice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykQ2GWHSn2M1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ba196d8-d128-4703-f574-fffb7745e92e"
      },
      "source": [
        "# utlizamos neste notebook a biblioteca nltk para fazer transformações no texto com a finalidade de classificar este\n",
        "# texto. A biblioteca spacy também possui um corpus de stopwords, portanto vamos olhar essas stopwords desta biblioteca\n",
        "\n",
        "# numero de palavras no corpus\n",
        "print('Stopwords spacy: ', len(nlp.Defaults.stop_words))\n",
        "\n",
        "stops_nltk = list(nlp.Defaults.stop_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stopwords spacy:  413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGc6XAPNn2M3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8be17c06-e7a8-4098-e677-379b67290fb9"
      },
      "source": [
        "# stopwords do SpaCy \n",
        "# examinando as stopwords deste corpus identificamos muitos termos que são comuns\n",
        "# no português de Portugal, como no exemplo abaixo. Estas palavras raramente são\n",
        "# encontradas em textos escritos no português Brasileiro, por isso todos os testes\n",
        "# foram realizados utilizando somente o corpus de stopwords da biblioteca nltk\n",
        "stops_nltk[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['estivestes', 'fazeis']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df8KLEGEwLKQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}